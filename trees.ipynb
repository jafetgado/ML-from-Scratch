{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    \"\"\"\n",
    "    Represents a single node in a decision tree.\n",
    "\n",
    "    Attributes:\n",
    "    - feature_index (int or None): Index of the feature to split on at this node.\n",
    "        None if the node is a leaf.\n",
    "    - threshold (float or None): Threshold value used to split the feature.\n",
    "        None if the node is a leaf.\n",
    "    - left (TreeNode or None): Left child node (samples that satisfy the split condition).\n",
    "    - right (TreeNode or None): Right child node (samples that do not satisfy the condition).\n",
    "    - value (int or float or None): Class label for classification or predicted value for \n",
    "        regression. Only set for leaf nodes.\n",
    "\n",
    "    Methods:\n",
    "    - is_leaf(): Returns True if the node is a leaf (i.e., has a predicted value).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  \n",
    "        self.threshold = threshold          \n",
    "        self.left = left                    \n",
    "        self.right = right                  \n",
    "        self.value = value                  \n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None                 \n",
    "\n",
    "    # Gini impurity measures how \"pure\" a node is\n",
    "    def _gini_impurity(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)  # Count each class\n",
    "        probs = counts / counts.sum()                 # Calculate class probabilities\n",
    "        return 1 - np.sum(probs ** 2)                 # Gini formula\n",
    "\n",
    "    # Find the best feature and threshold to split the data\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')      # Initialize best Gini as infinity\n",
    "        best_feature = None           # Track best feature index\n",
    "        best_threshold = None         # Track best threshold for splitting\n",
    "\n",
    "        for feature_index in range(X.shape[1]):  # Iterate through each feature\n",
    "            sorted_indices = np.argsort(X[:, feature_index])  # Sort feature values\n",
    "            X_sorted, y_sorted = X[sorted_indices], y[sorted_indices]\n",
    "\n",
    "            # Try all possible split points between unique values\n",
    "            for i in range(1, len(X)):\n",
    "                threshold = (X_sorted[i - 1, feature_index] + X_sorted[i, feature_index]) / 2\n",
    "\n",
    "                # Create masks for splitting\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = X[:, feature_index] > threshold\n",
    "\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                # Skip invalid splits\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Compute weighted Gini impurity of the split\n",
    "                gini_left = self._gini_impurity(y_left)\n",
    "                gini_right = self._gini_impurity(y_right)\n",
    "                weighted_gini = (len(y_left) * gini_left + len(y_right) * gini_right) / len(y)\n",
    "\n",
    "                # Update if current split is better\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold  # Return best split\n",
    "\n",
    "    # Recursively build the decision tree\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # If node is pure or max depth reached, return a leaf node\n",
    "        if len(set(y)) == 1 or depth >= self.max_depth:\n",
    "            leaf_value = np.bincount(y).argmax()  # Most common class\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        # Find best split\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "\n",
    "        # If no split found, return a leaf\n",
    "        if feature_index is None:\n",
    "            leaf_value = np.bincount(y).argmax()\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        # Split the data based on the best threshold\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_child = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_child = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        # Return the decision node\n",
    "        return TreeNode(feature_index, threshold, left_child, right_child)\n",
    "\n",
    "    # Fit the tree to training data\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, 0)  # Start at depth 0\n",
    "\n",
    "    # Predict one sample by traversing the tree\n",
    "    def _predict_one(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value  # Return class label if leaf\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_one(x, node.left)  # Go left\n",
    "        else:\n",
    "            return self._predict_one(x, node.right)  # Go right\n",
    "\n",
    "    # Predict multiple samples\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n",
    "\n",
    "    # Print the tree structure\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        indent = \"  \" * depth  # Indentation for visualization\n",
    "        if node.is_leaf():\n",
    "            print(f\"{indent}Leaf: Predict {node.value}\")\n",
    "        else:\n",
    "            print(f\"{indent}Feature[{node.feature_index}] <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Main class for the Decision Tree classifier\n",
    "class DecisionTreeClassifierScratch:\n",
    "    def __init__(self, max_depth=3):\n",
    "        self.max_depth = max_depth          # Maximum depth of the tree\n",
    "        self.root = None                    # Root node of the tree\n",
    "\n",
    "    # Gini impurity measures how \"pure\" a node is\n",
    "    def _gini_impurity(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)  # Count each class\n",
    "        probs = counts / counts.sum()                 # Calculate class probabilities\n",
    "        return 1 - np.sum(probs ** 2)                 # Gini formula\n",
    "\n",
    "    # Find the best feature and threshold to split the data\n",
    "    def _best_split(self, X, y):\n",
    "        best_gini = float('inf')      # Initialize best Gini as infinity\n",
    "        best_feature = None           # Track best feature index\n",
    "        best_threshold = None         # Track best threshold for splitting\n",
    "\n",
    "        for feature_index in range(X.shape[1]):  # Iterate through each feature\n",
    "            sorted_indices = np.argsort(X[:, feature_index])  # Sort feature values\n",
    "            X_sorted, y_sorted = X[sorted_indices], y[sorted_indices]\n",
    "\n",
    "            # Try all possible split points between unique values\n",
    "            for i in range(1, len(X)):\n",
    "                threshold = (X_sorted[i - 1, feature_index] + X_sorted[i, feature_index]) / 2\n",
    "\n",
    "                # Create masks for splitting\n",
    "                left_mask = X[:, feature_index] <= threshold\n",
    "                right_mask = X[:, feature_index] > threshold\n",
    "\n",
    "                y_left, y_right = y[left_mask], y[right_mask]\n",
    "\n",
    "                # Skip invalid splits\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Compute weighted Gini impurity of the split\n",
    "                gini_left = self._gini_impurity(y_left)\n",
    "                gini_right = self._gini_impurity(y_right)\n",
    "                weighted_gini = (len(y_left) * gini_left + len(y_right) * gini_right) / len(y)\n",
    "\n",
    "                # Update if current split is better\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold  # Return best split\n",
    "\n",
    "    # Recursively build the decision tree\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        # If node is pure or max depth reached, return a leaf node\n",
    "        if len(set(y)) == 1 or depth >= self.max_depth:\n",
    "            leaf_value = np.bincount(y).argmax()  # Most common class\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        # Find best split\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "\n",
    "        # If no split found, return a leaf\n",
    "        if feature_index is None:\n",
    "            leaf_value = np.bincount(y).argmax()\n",
    "            return TreeNode(value=leaf_value)\n",
    "\n",
    "        # Split the data based on the best threshold\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "\n",
    "        # Recursively build left and right subtrees\n",
    "        left_child = self._build_tree(X[left_mask], y[left_mask], depth + 1)\n",
    "        right_child = self._build_tree(X[right_mask], y[right_mask], depth + 1)\n",
    "\n",
    "        # Return the decision node\n",
    "        return TreeNode(feature_index, threshold, left_child, right_child)\n",
    "\n",
    "    # Fit the tree to training data\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, 0)  # Start at depth 0\n",
    "\n",
    "    # Predict one sample by traversing the tree\n",
    "    def _predict_one(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            return node.value  # Return class label if leaf\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._predict_one(x, node.left)  # Go left\n",
    "        else:\n",
    "            return self._predict_one(x, node.right)  # Go right\n",
    "\n",
    "    # Predict multiple samples\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_one(x, self.root) for x in X])\n",
    "\n",
    "    # Print the tree structure\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        indent = \"  \" * depth  # Indentation for visualization\n",
    "        if node.is_leaf():\n",
    "            print(f\"{indent}Leaf: Predict {node.value}\")\n",
    "        else:\n",
    "            print(f\"{indent}Feature[{node.feature_index}] <= {node.threshold}\")\n",
    "            self.print_tree(node.left, depth + 1)\n",
    "            self.print_tree(node.right, depth + 1)\n",
    "\n",
    "# Example usage\n",
    "X = np.array([\n",
    "    [22], [25], [47], [52], [46], [56], [23], [24]\n",
    "])\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 0, 0])  # Binary classification labels\n",
    "\n",
    "# Create and train the classifier\n",
    "clf = DecisionTreeClassifierScratch(max_depth=3)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Print the structure of the trained tree\n",
    "clf.print_tree()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
